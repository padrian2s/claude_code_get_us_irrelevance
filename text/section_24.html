<div class="page-content">
  <h2>Section 24: Geopolitics — Export Controls, China & the Post-AI World Order</h2>

  <div class="transcript">
    <span class="speaker speaker--host">Dwarkesh:</span>
    <p>Let me now ask you about making AI go well. It seems like whatever vision we have about how AI goes well has to be compatible with two things: the ability to build and run AIs is diffusing extremely rapidly, and the population of AIs will also increase very rapidly. What is a vision for a world in which we have an equilibrium?</p>

    <span class="speaker speaker--guest">Dario:</span>
    <p>In the short run, we have a limited number of players now. We need to put in place the safeguards. We need to make sure everyone does the right alignment work. We need to make sure everyone has bioclassifiers. In the long run, we need some architecture of governance that preserves human freedom, but also allows us to govern a very large number of human systems, AI systems, hybrid human-AI companies.</p>

    <span class="speaker speaker--guest">Dario (on export controls):</span>
    <p>A thing I've been trying to fight for is export controls on chips to China. That's in the national security interest of the US. That's squarely within the policy beliefs of almost everyone in Congress of both parties. The case is very clear. The counterarguments against it, I'll politely call them fishy. Yet it doesn't happen and we sell the chips because there's so much money riding on it.</p>

    <span class="speaker speaker--host">Dwarkesh:</span>
    <p>Why shouldn't the US and China both have a "country of geniuses in a data center"?</p>

    <span class="speaker speaker--guest">Dario:</span>
    <p>My worry is if the world gets carved up into two pieces, one of those two pieces could be authoritarian or totalitarian in a way that's very difficult to displace. My worry is about governments. If the world gets carved up into two pieces, one government could use AI for total surveillance, thought policing, and population control. My interest is in making the negotiation about the post-AI world order be one in which classical liberal democracy has a strong hand.</p>

    <span class="speaker speaker--guest">Dario (on dissolving authoritarianism):</span>
    <p>Could there be developments — either that naturally happen as a result of AI, or that we could make happen — that create an equilibrium where it becomes infeasible for authoritarian countries to deny their people private use of the benefits of the technology? Are there equilibria where we can give everyone in an authoritarian country their own AI model that defends them from surveillance? I don't know. But what if we could try again with the knowledge of how many things could go wrong, and that this is a different technology?</p>

    <span class="speaker speaker--guest">Dario (on the developing world):</span>
    <p>I said we shouldn't build data centers in China, but there's no reason we shouldn't build data centers in Africa. In fact, I think it'd be great to build data centers in Africa. There's no reason we can't build an AI-driven pharmaceutical industry. Let's make sure some of those startups happen in the developing world so that fast growth can happen there as well.</p>
  </div>

  <div class="commentary">
    <h3>Explained Simply</h3>

    <div class="commentary-section">
      <h4>The Core Dilemma</h4>
      <p>Here's the fundamental tension: AI is the most powerful technology ever created, and it's spreading fast. Some of the people and governments who will get it have values deeply opposed to human freedom. How do you make the benefits of AI universal while preventing the technology from being weaponized by authoritarian regimes? Dario doesn't pretend to have a clean answer, but he lays out the landscape clearly.</p>
    </div>

    <div class="highlight-box">
      <strong>Dario's geopolitical framework:</strong><br>
      <strong>Short term (now):</strong> Small number of AI companies. Focus on safeguards — alignment work, bioclassifiers, transparency standards. The window is closing to get this right.<br>
      <strong>Medium term:</strong> "Critical moments" where one country or coalition reaches capabilities that confer decisive advantages in cybersecurity, military applications, or surveillance. This is when the world order gets renegotiated, implicitly or explicitly.<br>
      <strong>Long term:</strong> Need a governance architecture that preserves freedom while managing vast numbers of AI systems. Nobody knows what this looks like yet.
    </div>

    <div class="commentary-section">
      <h4>The China Question</h4>
      <p>Dario is unusually direct here. He advocates for export controls on chips to China — and is frustrated that they aren't being enforced, despite bipartisan support, because "there's so much money riding on it." His reasoning: not that Chinese people shouldn't benefit from AI, but that the Chinese government could use powerful AI for permanent totalitarian control. The distinction between a government and its people matters here. He explicitly says we should build data centers in Africa and the developing world. The line isn't developed vs. developing — it's democratic vs. authoritarian.</p>
    </div>

    <div class="warning-box">
      <strong>The "dissolving effect" — a hope, not a plan:</strong> Dario floats an intriguing but uncertain idea: could AI technology inherently dissolve authoritarian structures? Could you give every citizen in an authoritarian country their own AI that defends them from surveillance? He acknowledges we hoped the internet would do this and it didn't. But he argues AI is a fundamentally different technology and it's worth trying again. This is more of a research agenda than a policy position — an acknowledgment that we need creative new approaches to an ancient problem.
    </div>

    <div class="commentary-section">
      <h4>AI and the Developing World</h4>
      <p>This is where Dario's vision gets most optimistic and most practical. Traditional economic development relies on cheap labor — build factories, employ workers, grow the economy. In a world where AI replaces much of that labor, developing countries lose their main path to growth. Dario's alternative: bring the AI infrastructure TO the developing world. Build data centers in Africa. Seed AI-powered pharmaceutical companies in developing nations. Make sure the humans supervising AI systems during the transition include people in the developing world. It's an attempt to prevent AI from becoming yet another technology that widens the gap between rich and poor countries.</p>
    </div>

    <div class="quote-box">
      <strong>"What will not come easily is distribution of benefits, distribution of wealth, political freedom. These are the things that are going to be hard to achieve."</strong><br><br>
      This might be the most important line in the entire interview. Dario is saying the technology will deliver the goods — cures, productivity, knowledge. That part is almost guaranteed by the exponential. What ISN'T guaranteed is that those goods reach everyone, that the wealth gets shared, and that freedom is preserved. The hard problem of AI isn't building it. It's making sure it helps everyone.
    </div>
  </div>
</div>
